---
title: "Regression Basics Assignment"
author: "Demetrius Green"
date: "`r Sys.Date()`"
output:
  pdf_document: default
---
In this assignment we will start exploring some truly big data. Touringplans.com is a website that uses big data methods in order to solve life's most important problems...predicting Disney World ride wait times.

For this assignment we will predict posted wait times at a classic Disney World ride, Pirates of the Caribbean. There are many, many factors that affect wait times and crowd levels...time of day, day of the week, season of the year, special events, ticket prices, etc etc etc.

During the course of the semester, we will investigate several such factors. Currently we will begin with some basic data importing and cleaning. Please review the metadata file as well as the descriptions of all variables in the "Folder" at the top of the main course website.

```{r libraries, warning=FALSE, message=FALSE}
#load libraries
library(tidyverse)
library(readxl)
library(psych)
library(lubridate)
```

In the first step, we will be reading in the raw files for the Pirates of Carribean attraction and meta dat a.

```{r data_import, message=F, warning=F}
#read in pirates of carribean data
pir_raw = read_csv('../data/disneydata/pirates_of_caribbean.csv', col_names = T)

#read in metaata
meta_raw = read_csv('../data/disneydata/metadata.csv', col_names = TRUE, 
                    #change guess arg to better guage col type
                    guess_max = 5000)
```

**Instructions**: Do the things you should be doing without instruction - clean the data to remove out of bound and missing values. Do some plots.

The data wrangling efforts below involve changing the 'date' feature from a character to an actual date that is recognized by R. The 'SPOSTMIN' and 'SACTMIN' features were the posted wait times and actual wait time for the attraction, respectively. Since no observation had both within the data, I decided to combine them into a single feature aptly named 'waittime'. The original columns were then removed as well as the rows containing '-999' because this indicated the attraction was closed.

Additionally, I grouped the data by dates and calculated the median 'waittime'; this metric made more sense because the median can be more robust than the average, especially when the range of values can be relatively large (e.g., 5 minutes of waiting vs 45 minutes of waiting). 

```{r df_wrangling}
#wrangle pirate of carribean data
pir_dat = pir_raw %>% 
    replace_na(
        list('SPOSTMIN' = 0, 'SACTMIN' = 0)) %>% 
    mutate(
        'date' = mdy(date),
        'waittime' = SPOSTMIN + SACTMIN, 
        'SPOSTMIN' = NULL, 
        'SACTMIN' = NULL) %>% 
    filter(waittime != -999) #ride closed indicator

#group dates for plots
date_grps = pir_dat %>% 
    group_by(date) %>% 
    summarise(waittime = median(waittime)) #use median
```

To visualize the data, a line graph was create to show the median waittime over all the dates incldued within the dataset, essentially making the data time series. 

```{r line_graph, results='asis', warning=F, message=F}
#create a line graph of wait time over the years
date_grps %>% 
    ggplot(aes(x = date, y = waittime)) + 
    geom_line(color = 'dark blue', size = .25) +
    stat_smooth(color = 'red', fill = 'red', method = ) + 
    scale_x_date(date_labels = '%b %y', date_breaks = '1 month') + 
    labs(
        title = 'Disney\'s Pirates of the Carribean',
        subtitle = 'Median per Day Wait Time (2012-2018)',
        x = 'Date', 
        y = 'Wait Time (minutes)') + 
    annotate(
        geom = 'text', 
        x = as.Date('2015-06-08'), 
        y = 35, 
        label = 'No \n data...', 
        size = 2) + 
    annotate(
        geom = 'point', 
        x = as.Date('2015-08-01'), 
        y = 28, 
        size = 12, shape = 21, fill = 'transparent') + 
    theme_light() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 5))
```

The meta data incldued much more information regarding the attractions, but not every variable was necessary for any of our analyses. Reading in the metadata was the next step. 

*It should be noted that the code below includes recoding features because although the month of the year and day of the week are by default numerical, they are not actually true discrete or continuous variables.*

```{r metadata}
#wrangle metadata before merging
meta2 = meta_raw %>% 
  rename_all(list(tolower)) %>% #changes column names to lowercase
  select(date, dayofweek, weekofyear, monthofyear, wdwmeantemp) %>% 
  mutate(date = mdy(date))
    #use to recode values into specific factors...not useful in this assignment
    #        dayofweek = recode(dayofweek, 
    #                           `1` = 'Thurs', `2` = 'Fri', `3` = 'Sat', 
    #                           `4` = 'Sun', `5` = 'Mon', `6` = "Tues", 
    #                           `7` = 'Wed'), 
    #        monthofyear = recode(monthofyear, 
    #                             `1` = 'Jan', `2` = 'Feb', `3` = 'Mar', 
    #                             `4` = 'Apr', `5` = 'May', `6` = 'Jun',
    #                             `7` = 'July', `8` = 'Aug', `9` = 'Sept', 
    #                             `10` = 'Oct', `11` = 'Nov', `12` = 'Dec')
    #        ) %>% 
    # mutate_at(c('dayofweek', 'monthofyear'), list(as.factor))
```

This code includes the *drop_na()* function to remove rows with missing values following the merging of the Pirates of Carribean attraction data with the metadata via *merge()*.

```{r}
#merge dfs by date; rm 2nd column of datetimes
mrg_dat = merge(pir_dat, meta2, by = 'date')[, -2] %>% 
    drop_na() #rm NA values
```

**Instructions:** Run the pairs command to see all correlations in the database. 

```{r, results='asis', warning=F, message=FALSE}
library(GGally)
ggpairs(data.frame(mrg_dat[, -1]))
```

\pagebreak
**Instructions:** For the assignment, predict posted wait times from the variables you just coded, at least one interaction, and at least one variable from the metadata file. The independent variables I chose are listed within the formula.

```{r}
#complete regression analysis
fit = lm(waittime ~ dayofweek + weekofyear + monthofyear + wdwmeantemp + 
             weekofyear*wdwmeantemp, data = mrg_dat)
summary(fit)
```

